<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
  <style>
    .navA{
      display: inline-block;
      margin-right: 13px;
      font-size: 16px;
      font-weight: 700;
      color: #000;
      text-decoration: none;
      padding: 5px ;
      border: #000 1px solid;
    }
    .navA:hover{
      color: #fff;
      background-color: #000;
    }
  </style>

  <title>Shaoyi Huang</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--   <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shaoyi Huang</name>
              </p>
              <p>Shaoyi is a 4-th year Ph.D. student in the <a href="https://www.cse.uconn.edu/">School of Computing</a> at <a href="https://www.cse.uconn.edu/">University of Connecticut</a>, 
                working with Prof. <a href="https://caiwending.cse.uconn.edu/">Caiwen Ding</a> and Prof. <a href="https://khan.engr.uconn.edu/">Omer Khan</a> as a member of <a href="https://caiwending.cse.uconn.edu/">Intelligent & Efficient Systems Laboratory</a>. 
                Her research agenda is grounded in advancing <b>AI systems</b>, including algorithm-system co-design for AI acceleration, emerging deep learning models inference acceleration (i.e., Transformer and LLM),  privacy preserving machine learning, and machine learning for EDA.
              </p>

              <p>
                Her work on FPGA-based language models acceleration through sparse attention and dynamic pipelining won <b>DAC'22 Publicity Paper Award</b>. She is the recipient of <b>Cigna Graduate Fellowship</b> in 2021, <b>Eversource Energy Graduate Fellowship</b> in 2022, and <b>Synchrony Fellowship</b> in 2022. 
                She was awarded both <b>Predoctoral Prize for Research Excellence</b> and <b>GE Fellowship for Excellence</b> from UConn in 2022 and 2023. 
                She was invited to serve as a student panelist to share experience with female researchers and K-12 students at <b>The 6th Workshop for Women in Hardware and Systems Security (WISE)</b>.
                Shaoyi’s work has been published in high-impact conferences such as HPCA, ASPLOS, SC, DAC, ICCAD, ACL, ICCV, NeurIPS, IJCAI, etc.
              </p>
<!--               <p> During 2019-2020, I worked as an algorithm engineer at <a href="https://www.huawei.com/en/">Huawei Technologies</a>, where I focused on machine learning for graphs and causal inference. My role involved developing intelligent alarm algorithms and an artificial intelligent fault management framework.
                During summer 2021, I worked with <a href="https://moffett.ai/"> Moffett AI</a> on developing effcient inference algorithm for language models.
                In summer 2022, I was a research intern in <a href="https://www.tiktok.com/en/">TikTok</a>, studying training acceleration on Transformer-based models.
                Since January 2023, I have been working with <a href="https://www.src.org/">Semiconductor Research Corporation</a> (SRC) to investigate extreme sparsity in training and inference for Graph Neural Networks, with the aim of achieving high-performance scaling on machines with a large core count.
              </p> -->
              <p style="color:red;font-weight: bold;">
                Shaoyi is on the 2024 academic job market, please do not hesitate to reach out for any relevant job openings.
              </p>
              <p style="text-align:center">
                <a href="mailto:shaoyi.huang@uconn.edu">Email</a> &nbsp/&nbsp
                <a href="files/CV_ShaoyiHuang.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Ybk2L10AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shaoyiHusky">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shaoyi-huang-719ab611b/">LinkedIn</a>
              </p>
            </td>

            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Shaoyi.jpeg"><img style="width:60%;max-width:60%" alt="profile photo" src="images/Shaoyi.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <div class="navbar" style="padding-left: 18px;">
          <a href="#Research" class="navA">Research</a>
          <a href="#News" class="navA">News</a>
          <a href="#Publications" class="navA">Publications</a>
          <a href="#Services" class="navA">Services</a>
          <a href="#Teaching" class="navA">Teaching</a>
          <a href="#Internship" class="navA">Internship</a>
          <a href="#Talks" class="navA">Talks</a>
          <a href="#Honors" class="navA">Awards</a>
        </div>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
  
            <td width="100%" valign="middle">
  
              <heading id="Research"><b>Research Interests</b></heading>
  
              <ul>
              <li><p>
                <strong>Sparsity & Parallelism Exploitation Sparse Training</strong>
                [<a href="https://www.shaoyihuang.com/" target="_blank">HPCA'24</a>],
                [<a href="https://www.shaoyihuang.com/" target="_blank">ASPLOS'24</a>], 
                [<a href="https://browse.arxiv.org/pdf/2211.16667.pdf" target="_blank">DAC'23(a)</a>], 
                [<a href="https://browse.arxiv.org/pdf/2304.12214.pdf" target="_blank">DAC'23(b)</a>], 
                [<a href="https://browse.arxiv.org/pdf/2209.04766.pdf" target="_blank">ICCD'22</a>]
              </p>

                <li><p>
                <strong>Emerging Deep Learning Models Inference Acceleration</strong>
                [<a href="https://browse.arxiv.org/pdf/2308.11825.pdf" target="_blank">ICCAD'23</a>], 
                [<a href="https://browse.arxiv.org/pdf/2110.08190.pdf" target="_blank">ACL'22</a>], 
                [<a href="https://browse.arxiv.org/pdf/2208.03646.pdf" target="_blank">DAC'22</a>], 
                [<a href="https://khan.engr.uconn.edu/pubs/iccd22-reram-gnn.pdf" target="_blank">ICCD'22</a>], 
                [<a href="https://dl.acm.org/doi/pdf/10.1145/3458817.3476138" target="_blank">SC'21</a>], 
                [<a href="https://browse.arxiv.org/pdf/2110.10030.pdf" target="_blank">ICCAD'21</a>], 
                [<a href="https://browse.arxiv.org/pdf/2309.14331.pdf" target="_blank">ISQED'21</a>],
                [<a href="https://dl.acm.org/doi/abs/10.1145/3453688.3461740" target="_blank">GLSVLSI'21</a>],
                <font color="#1772d0">[DAC'24(a) submitted]</font>, 
                <font color="#1772d0">[DAC'24(b) submitted]</font>
                </p>

                <li><p>
                <strong>Privacy Preserving Machine Learning</strong>
                [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.pdf" target="_blank">ICCV'23</a>], 
                [<a href="https://arxiv.org/pdf/2309.14331.pdf" target="_blank">NeurIPS'23</a>], 
                [<a href="https://ieeexplore.ieee.org/abstract/document/10020711" target="_blank">IEEE BigData'23</a>],
                <font color="#1772d0">[AAAI'24 submitted]</font>
                </p>

                <li><p>
                <strong>Machine Learning for EDA</strong>
                <font color="#1772d0">[ASPLOS'24 submitted]</font>
                </p>
                
                 
<!--                 <li><p>
                <strong>Domains: Natural Language Processing, Computer Vision, Computer Architecture, EDA</strong>
                </p>  -->
  
              </ul>
            </td>
          </tr>

        <tr>
          <td>
            <heading id="News"><b>News</b></heading>
              <div class="list scroll">
              <ul>
                <li>10/2023: One paper was accepted to <b>ASPLOS 2024</b>.</li>
                <li>10/2023: One paper was accepted to <b>HPCA 2024</b>.</li>
                <li>10/2023: Received travel grant from <a href="https://cacc.uconn.edu/">CACC</a>. Thanks, CACC!</li>
                <li>09/2023: Honored to be invited to be the student panelist and received student travel grant from WISE 2023.</li>
                <li>09/2023: One proposal on <b>Efficient Multi-party Computation-based Private Inference</b> was accepted to <b>WISE 2023</b> (The 6th Workshop for Women in Hardware and Systems Security).</li>
                <li>09/2023: One paper was accepted to <b>NeurIPS 2023</b>.</li>
                <li>09/2023: Honored to be invited to give a guest lecture at the <a href="https://www.rochester.edu/">University of Rochester</a>.</li>
                <li>09/2023: Invited to serve as a PC member for <b>SDM 2024</b>.</li>
                <li>09/2023: Honored to present at <b>TechCon</b> organized by <a href="https://www.src.org/">Semiconductor Research Corporation (SRC)</a>. See u in Austin.</li>
                <li>07/2023: One paper was accepted to <b>ICCAD 2023</b>.</li>
                <li>07/2023: One paper was accepted to <b>ICCV 2023</b>.</li>
                <li>07/2023: Invited to serve as a PC member for <b>AAAI 2024</b>.</li>
                <li>06/2023: Received the <b>GE Fellowship for Excellence</b> from <a href="https://grad.engr.uconn.edu/">UConn School of Engineering</a>.</li>
                <li>05/2023: Honored to give a talk and a poster presentation at <a href="https://www.src.org/">Semiconductor Research Corporation (SRC)</a> AIHW & CADT Annual Review in <a href="https://research.ibm.com/">IBM Research</a>. See u in San Jose.</li>
                <li>05/2023: Received the <b>Predoctoral Prize for Research Excellence</b> from <a href="https://www.cse.uconn.edu/">UConn CSE</a>.</li>
                <li>03/2023: Honored to be invited to give a talk at <b>MLNLP</b>.</li>
                <li>03/2023: One paper was accepted to <b>IJCAI 2023</b>.</li>
                <li>03/2023: Two papers on sparse training were accepted to <b>DAC 2023</b>. See u in San Francisco.</li>
                <li>01/2023: Invited to serve as a reviewer for the First Workshop on DL-Hardware Co-Design for AI Acceleration at <b>AAAI 2023</b>.</li>
                <li>12/2022: Invited to serve as a PC member for <b>KDD 2023</b>.</li>
                <li>08/2022: Received the <b>GE Fellowship for Excellence</b> from <a href="https://www.engr.uconn.edu/">the School of Engineering</a>. Thanks for the support!</li>
                <li>07/2022: Invited to serve as a PC member for <b>AAAI 2023</b>.</li>
                <li>07/2022: Received the <b>Synchrony Fellowship</b> from <a href="https://cacc.uconn.edu/">Connecticut Advanced Computing Center</a>. Thanks, CACC!</li>
                <li>05/2022: Started to work at <b>TikTok (ByteDance)</b> as a research intern.</li>
                <li>05/2022: Received the <b>Predoctoral Prize for Research Excellence</b> from <a href="https://www.cse.uconn.edu/">UConn CSE</a>.</li>
                <li>05/2022: Received the Eversource Energy Graduate Fellowship from <a href="https://www.eversource.uconn.edu/">Eversource Energy Center</a>. Thanks, Eversource!</li>
                <li>04/2022: Our <b>DAC 22</b> paper “A Length Adaptive Algorithm-Hardware Co-design of Transformer on FPGA Through Sparse Attention and Dynamic Pipelining” was recognized as a <b>Publicity Paper</b>.</li>
                <li>02/2022: One paper was accepted to <b>ACL 2022</b>.</li>
                <li>02/2022: One paper was accepted to <b>DAC 2022</b>.</li>
                <li>02/2022: One paper was accepted to <b>ISQED 2022</b>.</li>
                <li>08/2021: Received the Cigna Graduate Fellowship from UConn CSE. Thanks, Cigna!</li>
                <li>07/2021: One paper was accepted to <b>ICCAD 2021</b>.</li>
                <li>06/2021: One paper was accepted to <b>SC 2021</b>.</li>
                <li>04/2021: Three papers were accepted to <b>GLSVLSI 2021</b>.</li>
                <li>02/2021: One paper was accepted to <b>ISQED 2021</b>.</li>
              </ul>
              </div>
          </td>
        </tr>
        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading id="Publications"><b>Selected Publications</b></heading>
              <h2><a href="https://scholar.google.com/citations?user=_peZ1vIAAAAJ&hl=en">Full publication list</a></h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:12px;width:100%;vertical-align:middle">
              <h2>2023</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/MaxK.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <b>MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training</b>
              </a>
              <br>
              H. Peng, X. Xie, K. Shivdikar, M. A. Hasan, J. Zhao, <b>S. Huang</b>, O. Khan, D. Kaeli, C. Ding
              <br>
              <b>[ASPLOS 2024]</b>
              <a href="https://www.shaoyihuang.com/">Paper</a> / <a href="https://www.shaoyihuang.com/">Code</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/PruneGNN.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <b>PruneGNN: An Optimized Algorithm-Hardware Framework for Graph Neural Network Pruning</b>
              </a>
              <br>
              D. Gurevin, <b>S. Huang</b>, M. Shan, M. A. Hasan, C. Ding, O. Khan
              <br>
              <b>[HPCA 2024]</b>
              <a href="https://www.shaoyihuang.com/">Paper</a> / <a href="https://www.shaoyihuang.com/">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/LinGCN.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <b>LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference</b>
              </a>
              <br>
              H. Peng, R. Ran, Y. Luo, J. Zhao, <b>S. Huang</b>, K. Thorat, T. Geng, C. Wang, X.lin Xu, W. Wen, C. Ding
              <br>
              <b>[NeurIPS 2023]</b>
              <a href="https://arxiv.org/pdf/2309.14331.pdf">Paper</a> / <a href="https://github.com/harveyp123/LinGCN-Neurips23">Code</a>
              <br>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/accel_GCN.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <b>Accel-GCN: High-Performance GPU Accelerator Design for Graph Convolution Networks</b>
              </a>
              <br>
              X. Xie, H. Peng, A. Hasan, <b>S. Huang</b>, J. Zhao, H. Fang, W. Zhang, T. Geng, O. Khan, C. Ding
              <br>
              <b>[ICCAD 2023]</b>
              <a href="https://arxiv.org/pdf/2308.11825.pdf">Paper</a> / <a href="https://github.com/xiexi1990/ICCAD-Accel-GCN">Code</a>
              <br>
            </td>
          </tr>

          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/autoRep.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>AutoReP: Automatic ReLU Replacement for Fast Private Network Inference</papertitle>
              </a>
              <br>
              H. Peng*, <b>S. Huang*</b>, T. Zhou*, Y. Luo, C. Wang, ..., T. Geng, K. Mahmood, W. Wen, X. Xu, C. Ding
              <br>
              <b>[ICCV 2023]</b>
              <a href="https://arxiv.org/pdf/2308.10134.pdf">Paper</a> / <a href="https://github.com/HarveyP123/AutoReP">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/peer_distillation.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Lossless Head Pruning through Automatic Peer Distillation for Large Language Models</papertitle>
              </a>
              <br>
               B. Li, Z. Wang, <b>S. Huang</b>, M. Bragin, J. Li, C. Ding
              <br>
              <b>[IJCAI 2023]</b>
              <a href="https://www.ijcai.org/proceedings/2023/0568.pdf">Paper</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/DST-EE.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Dynamic Sparse Training via Balancing the Exploration-Exploitation Trade-off</papertitle>
              </a>
              <br>
              <b>S. Huang</b>, B. Lei, D. Xu, H. Peng, Y. Sun, M. Xie, C. Ding
              <br>
              <b>[DAC 2023]</b>
              
              <a href="https://arxiv.org/pdf/2211.16667.pdf">Paper</a> / <a href="https://www.shaoyihuang.com/">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/NDSNN.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Neurogenesis Dynamics-inspired Spiking Neural Network Training Acceleration</papertitle>
              </a>
              <br>
              <b>S. Huang</b>, H. Fang, K. Mahmood, B. Lei, N. Xu, B. Lei, Y. Sun, D. Xu, W. Wen, C. Ding
              <br>
              <b>[DAC 2023]</b>
              
              <a href="https://arxiv.org/pdf/2304.12214.pdf">Paper</a> / <a href="https://www.shaoyihuang.com/">Code</a>
              <br>
            </td>
          </tr>	
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>2022</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/SPD.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="http://www.personal.psu.edu/dux19/" id="3DSP"> -->
              <a id="3DSP">
                <papertitle> Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm</papertitle>
              </a>
              <br>
              <b>S. Huang</b>, D. Xu, I. E. Yen, S. Chang, B. Li, C. Ding, et al.
              <br>
              <b>[ACL 2022]</b>
              <a href="https://arxiv.org/pdf/2110.08190.pdf">Paper</a> / <a href="https://github.com/shaoyiHusky/SparseProgressiveDistillation">Code</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/length_adaptive.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Length Adaptive Algorithm-Hardware Co-design of Transformer on FPGA Through Sparse Attention and Dynamic Pipelining</papertitle>
              </a>
              <br>
              H. Peng*, <b>S. Huang*</b>, S. Chen, B. Li, T. Geng, A, Li, W. Jiang, W, Wen, J, Bi, H. Liu, C. Ding
              <br>
              <b>[DAC 2022]</b>
              <a href="https://arxiv.org/pdf/2208.03646.pdf">Paper</a>
              <br>
            </td>
          </tr>
  
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/sparsification_GNN.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Sparsification of Graph Neural Networks</papertitle>
              </a>
              <br>
              H. Peng, D. Gurevin, <b>S. Huang</b>, T. Geng, W. Jiang, O. Khan, C. Ding
              <br>
              <b>[ICCD 2022]</b>
              
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978504">Paper</a> / <a href="https://github.com/HarveyP123/ICCD_SpTrn_SLR">Code</a>
              <br>
            </td>
          </tr>

<!--           <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/CoDG-ReRAM.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CoDG-ReRAM: An Algorithm-Hardware Co-design to Accelerate Semi-Structured GNNs on ReRAM</papertitle>
              </a>
              <br>
              Y. Luo, P. Behnam, K. Thorat, Z. Liu, H. Peng, <b>S. Huang</b>, S. Zhou, O. Khan, A. Tumanov, C. Ding, T. Geng
              <br>
              <b>[ICCD 2022]</b>
              
              <a href="https://khan.engr.uconn.edu/pubs/iccd22-reram-gnn.pdf>Paper</a>
              <br>
            </td>
          </tr> -->

          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/CoDG-ReRAM.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CoDG-ReRAM: An Algorithm-Hardware Co-design to Accelerate Semi-Structured GNNs on ReRAM</papertitle>
              </a>
              <br>
              Y. Luo, P. Behnam, K. Thorat, Z. Liu, H. Peng, <b>S. Huang</b>, S. Zhou, O. Khan, A. Tumanov, C. Ding, T. Geng
              <br>
              <b>[ICCD 2022]</b>
              
              <a href="https://khan.engr.uconn.edu/pubs/iccd22-reram-gnn.pdf">Paper</a>
              <br>
            </td>
          </tr>
  
          
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/20222_BigData_MIA_NLP.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Analyzing and Defending against Membership Inference Attacks in Natural Language Processing Classification</papertitle>
              </a>
              <br>
              Y. Wang, N. Xu, <b>S. Huang</b>, K. Mahmood, D. Guo, C. Ding, W. Wen, S. Rajasekaran
              <br>
              <b>[IEEE BigData 2022]</b>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020711">Paper</a>
              <br>
            </td>
          </tr>
        </tbody></table>
        
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>2021</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/ET.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>E.T.: Re-Thinking Self-Attention for Transformer Models on GPU</papertitle>
              </a>
              <br>
              S. Chen*, <b>S. Huang*</b>, S. Pandey, B. Li, G. Gao, C. Ding, H. Liu
              <br>
              <b>[SC 2021]</b>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3458817.3476138">Paper</a> / <a href="https://github.com/cctry/E.T.">Code</a>
              <br>
            </td>
          </tr>
  
          <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/ICCAD_2021.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization</papertitle>
              </a>
              <br>
              P. Qi, E. Sha, Q. Zhuge, H. Peng, <b>S. Huang</b>, Z. Kong, Y. Song, B. Li
              <br>
              <b>[ICCAD 2021]</b>
              <a href="https://arxiv.org/pdf/2110.10030.pdf">Paper</a>
              <br>
            </td>
          </tr>

        <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/hmc_tran.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HMC-Tran: A Tensor-core Inspired Hierarchical Model Compression for Transformer-based DNNs on GPU</papertitle>
              </a>
              <br>
              <b>S. Huang</b>, S. Chen, H. Peng, D. Manu, Z. Kong, G. Yuan, L. Yang, S. Wang, H. Liu, C. Ding
              <br>
              <b>[GLSVLSI 2021]</b>
              <a href="https://dl.acm.org/doi/abs/10.1145/3453688.3461740">Paper</a>
              <br>
            </td>
          </tr>

        <tr>
            <td style="padding:12px;width:25%;vertical-align:middle">
              <img src="images/Shaoyi/ISQED_2021.png" alt="3DSP" width="160" height="60" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Accelerating transformer-based deep learning models on fpgas using column balanced block pruning</papertitle>
              </a>
              <br>
              H. Peng, <b>S. Huang</b>, T. Geng, A. Li, W. Jiang, H. Liu, W. Wang, C. Ding
              <br>
              <b>[ISQED 2021]</b>
              
              <a href="https://wangshusen.github.io/papers/ISQED2021.pdf">Paper</a>
              <br>
            </td>
          </tr>
    
        </tbody></table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading id="Services">Professional Services</heading>

    <ul>
      <li>
        <b>Program Committee Member:</b>
          <ul>
            <li>
              SDM'24
            </li>
            <li>
              AAAI'24
            </li>
            <li>
              NeurIPS'23 Datasets and Benchmarks
            </li>
            <li>
              KDD'23
            </li>
            <li>
              AAAI'23
            </li>
            <li>
              DCAA'23
            </li>
          </ul>
      </li>
    </ul>

    <ul>
      <li>
        <b>Journal Reviewer:</b>
          <ul>
            <li>
              Neurocomputing
            </li>
            <li>
              Pattern Recognition
            </li>
            <li>
              Engineering Applications of Artificial Intelligence
            </li>
            <li>
              Neural Networks
            </li>
          </ul>
      </li>
    </ul>


        </td>
      </tr>
      </table>




    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading id="Teaching">Teaching Experiences</heading>

      <ul>
        <li>
          <b>Teaching Assistant at University of Connecticut</b>

              <ul>
                
              <li><p>
              CSE 4502/5717 - BigData Analytics, Spring 2023<br>
              Instructor: <a href="https://hesuining.weebly.com/">Prof. Suining He</a> &nbsp&nbsp
              </p>
                
              <li><p>
              CSE5819 - Introduction to Machine Learning, Fall 2022<br>
              Instructor: <a href="http://feimiao.org/index.html">Prof. Fei Miao</a> &nbsp&nbsp <!-- <br> -->
              </p>
              </ul>

          <li> <b>Teaching Assistant at University of Rochester</b>

              <ul>

              <li><p>
              Microcontroller, Spring 2018<br>
              Instructor: <a href="https://www.hajim.rochester.edu/ece/people/faculty/lin_qiang/index.html">Prof. Qiang Lin</a> &nbsp&nbsp <!-- <br> -->
              </p>
                
              <li><p>
              Circuits & Signals LAB, Fall 2017<br>
              Instructor: <a href="https://www.hajim.rochester.edu/ece/people/faculty/mottley_jack/index.html">Prof. Jack G. Mottley</a> &nbsp&nbsp
              </p>
                
              
              </ul>

        </li>
      </ul>

      <!-- <ul>
        <li>
          <b>Teaching Assistant at University of Rochester</b>
            <ul>
              <li><p>
                  CSC 791&591: Advanced Topics in Efficient Deep Learning<br>
                  Course Materials: <a href="https://d2l.ai/index.html">Dive into Deep Learning</a>
                  </p>
              </li>
            </ul>
        </li>
      </ul> -->

        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Internship">Internship</heading>

              <ul>
                <li><p>
                  [05/2022 - 08/2022] Research Intern, <a href="https://www.tiktok.com/en/">TikTok</a>, Austin, TX
                </p>
                  
                <li><p>
                  [05/2021 - 08/2021] Research Intern, <a href="https://moffett.ai/">Moffett AI</a>, Los Altos, CA
                </p>
              </ul>
          </td>
        </tr>
  </table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Talks">Talks</heading>

              <ul>
                <li><p>
                  <b>Student panelist</b> - The 6th Workshop for Women in Hardware and Systems Security<br>
                  Oct 2023, California State University, Fullerton, Fullerton, CA<br>
                </p>
                  
                <li><p>
                  <b>Towards Efficient Model Inference and Training</b><br>
                  Sep 2023, University of Rochester<br>
                  Guest Lecture of ECE 403-1: Advanced Computer Architecture for Machine Learning.<br>
                  Host: <a href="https://www.tonytgeng.com/">Prof. Tony Geng</a>
                </p>
                
                <li><p>
                  <b>Towards Efficient Training and Inference Under Pretrain-and-Finetune Paradigm</b><br>
                  Sep 2023, TechCon - Semiconductor Research Corporation (SRC), Austin, TX<br>
                  </p>
                
                <li><p>
                  <b>Exploring Extreme Sparsity in Training and Inference for Graph Neural Networks to Achieve High Performance
                    Scaling on Large Core Count Machines</b><br>
                  May 2023, Semiconductor Research Corporation (SRC) AIHW \& CADT Annual Review, IBM Research, San Jose, CA
                </p>
                
                <li><p>
                  <b>Towards Efficient Model Inference and Training</b><br>
                  Apr 2023, Machine Learning and Natural Language Processing Community (<a href="https://github.com/MLNLP-World">MNNLP</a>)
                </p>
              </ul>
          </td>
        </tr>
  </table>
        

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Honors">Honors and Awards</heading>


              <ul>
                <li>
                  NeurIPS Travel Grant from CACC, 2023
                </li>
                <li>
                  WISE Student Travel Award, 2023
                </li>
                <li>
                  GE Fellowship of Excellence, 2023
                </li>
                <li>
                  DAC Publicity Paper Award, 2023
                </li>
                <li>
                  Predoctoral Prize for Research Excellence, 2023
                </li>
                <li>
                  GE Fellowship for Excellence, 2022
                </li>
                <li>
                  Synchrony Fellowship, 2022
                </li>
                <li>
                  Predoctoral Prize for Research Excellence, 2022
                </li>
                <li>
                  Eversource Energy Graduate Fellowship, 2022
                </li>
                <li>
                  DAC Young Fellow, 2021
                </li>
                <li>
                  Cigna Graduate Fellowship, 2021
                </li>
              </ul>


          </td>
        </tr>
        </table>






  <div style="text-align: center;">
    <a href='https://clustrmaps.com/site/1bvmy'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=614099&w=288&t=tt&d=5NWaOG6r5FuVurTUjz6-Hzx4a7r99vZBkuamdg8-e8A&co=ffffff&ct=5c23bc'/></a>
  </div>


<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
        <table style="width:100%;border:0px;border-spacing:0px;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br><hr width=80%>
              <p style="text-align:right;font-size:small;color:gray;">
                Last updated on 12/2023 EDT.
                <br>
                <a href="https://jonbarron.info/">Webpage template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>


  
</body>

</html>
